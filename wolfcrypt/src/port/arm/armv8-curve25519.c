/* armv8-curve25519
 *
 * Copyright (C) 2006-2019 wolfSSL Inc.
 *
 * This file is part of wolfSSL.
 *
 * wolfSSL is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * wolfSSL is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1335, USA
 */

#ifdef HAVE_CONFIG_H
    #include <config.h>
#endif

#include <wolfssl/wolfcrypt/settings.h>
#include <wolfssl/wolfcrypt/fe_operations.h>
#include <stdint.h>

void fe_init()
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : 
        :
        : "memory"
    );
}

void fe_frombytes(fe out, const unsigned char* in)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "ldp	x2, x3, [x1]\n\t"
        "ldp	x4, x5, [x1, #16]\n\t"
        "and	x5, x5, #0x7fffffffffffffff\n\t"
        "stp	x2, x3, [x0]\n\t"
        "stp	x4, x5, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [out] "+r" (out), [in] "+r" (in)
        :
        : "memory", "x2", "x3", "x4", "x5", "x6"
    );
}

void fe_tobytes(unsigned char* out, const fe n)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "mov	x7, #19\n\t"
        "ldp	x2, x3, [x1]\n\t"
        "ldp	x4, x5, [x1, #16]\n\t"
        "adds	x6, x2, x7\n\t"
        "adcs	x6, x3, xzr\n\t"
        "adcs	x6, x4, xzr\n\t"
        "adc	x6, x5, xzr\n\t"
        "lsr	x6, x6, #63\n\t"
        "mul	x6, x6, x7\n\t"
        "adds	x2, x2, x6\n\t"
        "adcs	x3, x3, xzr\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adc	x5, x5, xzr\n\t"
        "and	x5, x5, #0x7fffffffffffffff\n\t"
        "stp	x2, x3, [x0]\n\t"
        "stp	x4, x5, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [out] "+r" (out), [n] "+r" (n)
        :
        : "memory", "x2", "x3", "x4", "x5", "x6", "x7"
    );
}

void fe_1(fe n)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Set one */
        "mov	x1, #1\n\t"
        "stp	x1, xzr, [x0]\n\t"
        "stp	xzr, xzr, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [n] "+r" (n)
        :
        : "memory", "x1"
    );
}

void fe_0(fe n)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Set zero */
        "stp	xzr, xzr, [x0]\n\t"
        "stp	xzr, xzr, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [n] "+r" (n)
        :
        : "memory"
    );
}

void fe_copy(fe r, const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Copy */
        "ldp	x2, x3, [x1]\n\t"
        "ldp	x4, x5, [x1, #16]\n\t"
        "stp	x2, x3, [x0]\n\t"
        "stp	x4, x5, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x2", "x3", "x4", "x5"
    );
}

void fe_cswap(fe a, fe b, int c)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Conditional Swap */
        "cmp	%[c], #1\n\t"
        "ldp	x3, x4, [x0]\n\t"
        "ldp	x5, x6, [x0, #16]\n\t"
        "ldp	x7, x8, [x1]\n\t"
        "ldp	x9, x10, [x1, #16]\n\t"
        "csel	x11, x3, x7, eq\n\t"
        "csel	x3, x7, x3, eq\n\t"
        "csel	x12, x4, x8, eq\n\t"
        "csel	x4, x8, x4, eq\n\t"
        "csel	x13, x5, x9, eq\n\t"
        "csel	x5, x9, x5, eq\n\t"
        "csel	x14, x6, x10, eq\n\t"
        "csel	x6, x10, x6, eq\n\t"
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "stp	x11, x12, [x1]\n\t"
        "stp	x13, x14, [x1, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [a] "+r" (a), [b] "+r" (b), [c] "+r" (c)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13", "x14"
    );
}

void fe_sub(fe r, const fe a, const fe b)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Sub */
        "ldp	x3, x4, [x1]\n\t"
        "ldp	x5, x6, [x1, #16]\n\t"
        "ldp	x7, x8, [x2]\n\t"
        "ldp	x9, x10, [x2, #16]\n\t"
        "subs	x3, x3, x7\n\t"
        "sbcs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x11, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x11, x12\n\t"
        "and	x13, x11, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x3, x3, x12\n\t"
        "adcs	x4, x4, x11\n\t"
        "adcs	x5, x5, x11\n\t"
        "adc	x6, x6, x13\n\t"
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a), [b] "+r" (b)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13"
    );
}

void fe_add(fe r, const fe a, const fe b)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Add */
        "ldp	x3, x4, [x1]\n\t"
        "ldp	x5, x6, [x1, #16]\n\t"
        "ldp	x7, x8, [x2]\n\t"
        "ldp	x9, x10, [x2, #16]\n\t"
        "adds	x3, x3, x7\n\t"
        "adcs	x4, x4, x8\n\t"
        "adcs	x5, x5, x9\n\t"
        "adc	x6, x6, x10\n\t"
        "mov	x12, #-19\n\t"
        "asr	x11, x6, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x11, x12\n\t"
        "and	x13, x11, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x3, x3, x12\n\t"
        "sbcs	x4, x4, x11\n\t"
        "sbcs	x5, x5, x11\n\t"
        "sbc	x6, x6, x13\n\t"
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a), [b] "+r" (b)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13"
    );
}

void fe_neg(fe r, const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "ldp	x2, x3, [x1]\n\t"
        "ldp	x4, x5, [x1, #16]\n\t"
        "mov	x6, #-19\n\t"
        "mov	x7, #-1\n\t"
        "mov	x8, #-1\n\t"
        "mov	x9, #0x7fffffffffffffff\n\t"
        "subs	x6, x6, x2\n\t"
        "sbcs	x7, x7, x3\n\t"
        "sbcs	x8, x8, x4\n\t"
        "sbc	x9, x9, x5\n\t"
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9"
    );
}

void fe_cmov(fe a, const fe b, int c)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "ldp	x4, x5, [x0]\n\t"
        "ldp	x6, x7, [x0, #16]\n\t"
        "ldp	x8, x9, [x1]\n\t"
        "ldp	x10, x11, [x1, #16]\n\t"
        "cmp	%[c], #1\n\t"
        "csel	x4, x4, x8, eq\n\t"
        "csel	x5, x5, x9, eq\n\t"
        "csel	x6, x6, x10, eq\n\t"
        "csel	x7, x7, x11, eq\n\t"
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [a] "+r" (a), [b] "+r" (b), [c] "+r" (c)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11"
    );
}

int fe_isnonzero(const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "mov	x6, #19\n\t"
        "ldp	x1, x2, [x0]\n\t"
        "ldp	x3, x4, [x0, #16]\n\t"
        "adds	x5, x1, x6\n\t"
        "adcs	x5, x2, xzr\n\t"
        "adcs	x5, x3, xzr\n\t"
        "adc	x5, x4, xzr\n\t"
        "lsr	x5, x5, #63\n\t"
        "mul	x5, x5, x6\n\t"
        "adds	x1, x1, x5\n\t"
        "adcs	x2, x2, xzr\n\t"
        "adcs	x3, x3, xzr\n\t"
        "adc	x4, x4, xzr\n\t"
        "and	x4, x4, #0x7fffffffffffffff\n\t"
        "orr	%[a], x1, x2\n\t"
        "orr	x3, x3, x4\n\t"
        "orr	%[a], %[a], x3\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [a] "+r" (a)
        :
        : "memory", "x1", "x2", "x3", "x4", "x5", "x6"
    );
    return (uint32_t)(size_t)a;
}

int fe_isnegative(const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "mov	x6, #19\n\t"
        "ldp	x1, x2, [x0]\n\t"
        "ldp	x3, x4, [x0, #16]\n\t"
        "adds	x5, x1, x6\n\t"
        "adcs	x5, x2, xzr\n\t"
        "adcs	x5, x3, xzr\n\t"
        "adc	x5, x4, xzr\n\t"
        "lsr	x5, x5, #63\n\t"
        "mul	x5, x5, x6\n\t"
        "ldr	x1, [x0]\n\t"
        "adds	x1, x1, x5\n\t"
        "and	%[a], x1, #1\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [a] "+r" (a)
        :
        : "memory", "x1", "x2", "x3", "x4", "x5", "x6"
    );
    return (uint32_t)(size_t)a;
}

void fe_cmov_table(fe* r, fe* base, signed char b)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        "sxtb	%[b], w2\n\t"
        "sbfx	x15, %[b], #7, #1\n\t"
        "sxtb	x16, w2\n\t"
        "eor	x16, x16, x15\n\t"
        "sub	x16, x16, x15\n\t"
        "mov	x3, #1\n\t"
        "mov	x4, xzr\n\t"
        "mov	x5, xzr\n\t"
        "mov	x6, xzr\n\t"
        "mov	x7, #1\n\t"
        "mov	x8, xzr\n\t"
        "mov	x9, xzr\n\t"
        "mov	x10, xzr\n\t"
        "mov	x11, xzr\n\t"
        "mov	x12, xzr\n\t"
        "mov	x13, xzr\n\t"
        "mov	x14, xzr\n\t"
        "cmp	x16, #1\n\t"
        "ldp	x17, x18, [x1]\n\t"
        "ldp	x19, x20, [x1, #16]\n\t"
        "ldp	x21, x22, [x1, #32]\n\t"
        "ldp	x23, x24, [x1, #48]\n\t"
        "ldp	x25, x26, [x1, #64]\n\t"
        "ldp	x27, x28, [x1, #80]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "cmp	x16, #2\n\t"
        "ldp	x17, x18, [x1, #96]\n\t"
        "ldp	x19, x20, [x1, #112]\n\t"
        "ldp	x21, x22, [x1, #128]\n\t"
        "ldp	x23, x24, [x1, #144]\n\t"
        "ldp	x25, x26, [x1, #160]\n\t"
        "ldp	x27, x28, [x1, #176]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "cmp	x16, #3\n\t"
        "ldp	x17, x18, [x1, #192]\n\t"
        "ldp	x19, x20, [x1, #208]\n\t"
        "ldp	x21, x22, [x1, #224]\n\t"
        "ldp	x23, x24, [x1, #240]\n\t"
        "ldp	x25, x26, [x1, #256]\n\t"
        "ldp	x27, x28, [x1, #272]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "cmp	x16, #4\n\t"
        "ldp	x17, x18, [x1, #288]\n\t"
        "ldp	x19, x20, [x1, #304]\n\t"
        "ldp	x21, x22, [x1, #320]\n\t"
        "ldp	x23, x24, [x1, #336]\n\t"
        "ldp	x25, x26, [x1, #352]\n\t"
        "ldp	x27, x28, [x1, #368]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "add	%[base], %[base], #0x180\n\t"
        "cmp	x16, #5\n\t"
        "ldp	x17, x18, [x1]\n\t"
        "ldp	x19, x20, [x1, #16]\n\t"
        "ldp	x21, x22, [x1, #32]\n\t"
        "ldp	x23, x24, [x1, #48]\n\t"
        "ldp	x25, x26, [x1, #64]\n\t"
        "ldp	x27, x28, [x1, #80]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "cmp	x16, #6\n\t"
        "ldp	x17, x18, [x1, #96]\n\t"
        "ldp	x19, x20, [x1, #112]\n\t"
        "ldp	x21, x22, [x1, #128]\n\t"
        "ldp	x23, x24, [x1, #144]\n\t"
        "ldp	x25, x26, [x1, #160]\n\t"
        "ldp	x27, x28, [x1, #176]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "cmp	x16, #7\n\t"
        "ldp	x17, x18, [x1, #192]\n\t"
        "ldp	x19, x20, [x1, #208]\n\t"
        "ldp	x21, x22, [x1, #224]\n\t"
        "ldp	x23, x24, [x1, #240]\n\t"
        "ldp	x25, x26, [x1, #256]\n\t"
        "ldp	x27, x28, [x1, #272]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "cmp	x16, #8\n\t"
        "ldp	x17, x18, [x1, #288]\n\t"
        "ldp	x19, x20, [x1, #304]\n\t"
        "ldp	x21, x22, [x1, #320]\n\t"
        "ldp	x23, x24, [x1, #336]\n\t"
        "ldp	x25, x26, [x1, #352]\n\t"
        "ldp	x27, x28, [x1, #368]\n\t"
        "csel	x3, x17, x3, eq\n\t"
        "csel	x4, x18, x4, eq\n\t"
        "csel	x5, x19, x5, eq\n\t"
        "csel	x6, x20, x6, eq\n\t"
        "csel	x7, x21, x7, eq\n\t"
        "csel	x8, x22, x8, eq\n\t"
        "csel	x9, x23, x9, eq\n\t"
        "csel	x10, x24, x10, eq\n\t"
        "csel	x11, x25, x11, eq\n\t"
        "csel	x12, x26, x12, eq\n\t"
        "csel	x13, x27, x13, eq\n\t"
        "csel	x14, x28, x14, eq\n\t"
        "add	%[base], %[base], #0x180\n\t"
        "sub	%[base], %[base], #0x180\n\t"
        "mov	x17, #-19\n\t"
        "mov	x18, #-1\n\t"
        "mov	x19, #-1\n\t"
        "mov	x20, #0x7fffffffffffffff\n\t"
        "subs	x17, x17, x11\n\t"
        "sbcs	x18, x18, x12\n\t"
        "sbcs	x19, x19, x13\n\t"
        "sbc	x20, x20, x14\n\t"
        "cmp	%[b], #0\n\t"
        "mov	x15, x3\n\t"
        "csel	x3, x7, x3, lt\n\t"
        "csel	x7, x15, x7, lt\n\t"
        "mov	x15, x4\n\t"
        "csel	x4, x8, x4, lt\n\t"
        "csel	x8, x15, x8, lt\n\t"
        "mov	x15, x5\n\t"
        "csel	x5, x9, x5, lt\n\t"
        "csel	x9, x15, x9, lt\n\t"
        "mov	x15, x6\n\t"
        "csel	x6, x10, x6, lt\n\t"
        "csel	x10, x15, x10, lt\n\t"
        "csel	x11, x17, x11, lt\n\t"
        "csel	x12, x18, x12, lt\n\t"
        "csel	x13, x19, x13, lt\n\t"
        "csel	x14, x20, x14, lt\n\t"
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "stp	x7, x8, [x0, #32]\n\t"
        "stp	x9, x10, [x0, #48]\n\t"
        "stp	x11, x12, [x0, #64]\n\t"
        "stp	x13, x14, [x0, #80]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [base] "+r" (base), [b] "+r" (b)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13", "x14", "x15", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27", "x28"
    );
}

void fe_mul(fe r, const fe a, const fe b)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Multiply */
        "ldp	x15, x16, [x1]\n\t"
        "ldp	x17, x18, [x1, #16]\n\t"
        "ldp	x19, x20, [x2]\n\t"
        "ldp	x21, x22, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x15, x19\n\t"
        "umulh	x7, x15, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x15, x20\n\t"
        "umulh	x8, x15, x20\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x16, x19\n\t"
        "umulh	x4, x16, x19\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x15, x21\n\t"
        "umulh	x4, x15, x21\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x16, x20\n\t"
        "umulh	x4, x16, x20\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x17, x19\n\t"
        "umulh	x4, x17, x19\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x15, x22\n\t"
        "umulh	x4, x15, x22\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x16, x21\n\t"
        "umulh	x4, x16, x21\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x17, x20\n\t"
        "umulh	x4, x17, x20\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x18, x19\n\t"
        "umulh	x4, x18, x19\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x16, x22\n\t"
        "umulh	x4, x16, x22\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x17, x21\n\t"
        "umulh	x4, x17, x21\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x18, x20\n\t"
        "umulh	x4, x18, x20\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x17, x22\n\t"
        "umulh	x4, x17, x22\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x18, x21\n\t"
        "umulh	x4, x18, x21\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x18, x22\n\t"
        "umulh	x4, x18, x22\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a), [b] "+r" (b)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13", "x14", "x15", "x16", "x17", "x18", "x19", "x20", "x21", "x22"
    );
}

void fe_sq(fe r, const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Square */
        "ldp	x14, x15, [x1]\n\t"
        "ldp	x16, x17, [x1, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x3, x14, x15\n\t"
        "umulh	x4, x14, x15\n\t"
        /*  A[0] * A[2] */
        "mul	x11, x14, x16\n\t"
        "umulh	x5, x14, x16\n\t"
        "adds	x4, x4, x11\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x11, x14, x17\n\t"
        "umulh	x6, x14, x17\n\t"
        "adds	x5, x5, x11\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x11, x15, x16\n\t"
        "umulh	x12, x15, x16\n\t"
        "adds	x5, x5, x11\n\t"
        "adcs	x6, x6, x12\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x11, x15, x17\n\t"
        "umulh	x12, x15, x17\n\t"
        "adds	x6, x6, x11\n\t"
        "adc	x7, x7, x12\n\t"
        /*  A[2] * A[3] */
        "mul	x11, x16, x17\n\t"
        "umulh	x8, x16, x17\n\t"
        "adds	x7, x7, x11\n\t"
        "adc	x8, x8, xzr\n\t"
        /* Double */
        "adds	x3, x3, x3\n\t"
        "adcs	x4, x4, x4\n\t"
        "adcs	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adcs	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x2, x14, x14\n\t"
        "umulh	x10, x14, x14\n\t"
        /*  A[1] * A[1] */
        "mul	x11, x15, x15\n\t"
        "umulh	x12, x15, x15\n\t"
        "adds	x3, x3, x10\n\t"
        "adcs	x4, x4, x11\n\t"
        "adc	x10, x12, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x11, x16, x16\n\t"
        "umulh	x12, x16, x16\n\t"
        "adds	x5, x5, x10\n\t"
        "adcs	x6, x6, x11\n\t"
        "adc	x10, x12, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x11, x17, x17\n\t"
        "umulh	x12, x17, x17\n\t"
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adc	x9, x9, x12\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "extr	x6, x6, x5, #63\n\t"
        "and	x5, x5, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x11, #19\n\t"
        "mul	x12, x11, x6\n\t"
        "umulh	x6, x11, x6\n\t"
        "adds	x2, x2, x12\n\t"
        "mul	x12, x11, x7\n\t"
        "umulh	x7, x11, x7\n\t"
        "adcs	x3, x3, x12\n\t"
        "mul	x12, x11, x8\n\t"
        "umulh	x8, x11, x8\n\t"
        "adcs	x4, x4, x12\n\t"
        "mul	x12, x11, x9\n\t"
        "umulh	x13, x11, x9\n\t"
        "adcs	x5, x5, x12\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x3, x3, x6\n\t"
        "adcs	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  Overflow */
        "extr	x13, x13, x5, #63\n\t"
        "mul	x13, x13, x11\n\t"
        "and	x5, x5, #0x7fffffffffffffff\n\t"
        "adds	x2, x2, x13\n\t"
        "adcs	x3, x3, xzr\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adc	x5, x5, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x13, x5, #63\n\t"
        "mul	x13, x13, x11\n\t"
        "and	x5, x5, #0x7fffffffffffffff\n\t"
        "adds	x2, x2, x13\n\t"
        "adcs	x3, x3, xzr\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adc	x5, x5, xzr\n\t"
        /* Store */
        "stp	x2, x3, [x0]\n\t"
        "stp	x4, x5, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x11", "x12", "x13", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x14", "x15", "x16", "x17"
    );
}

void fe_mul121666(fe r, fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Multiply by 121666 */
        "ldp	x2, x3, [x1]\n\t"
        "ldp	x4, x5, [x1, #16]\n\t"
        "mov	x13, #0xdb42\n\t"
        "movk	x13, #1, lsl 16\n\t"
        "mul	x6, x2, x13\n\t"
        "umulh	x7, x2, x13\n\t"
        "mul	x11, x3, x13\n\t"
        "umulh	x12, x3, x13\n\t"
        "adds	x7, x7, x11\n\t"
        "adc	x8, xzr, x12\n\t"
        "mul	x11, x4, x13\n\t"
        "umulh	x12, x4, x13\n\t"
        "adds	x8, x8, x11\n\t"
        "adc	x9, xzr, x12\n\t"
        "mul	x11, x5, x13\n\t"
        "umulh	x12, x5, x13\n\t"
        "adds	x9, x9, x11\n\t"
        "adc	x12, xzr, x12\n\t"
        "mov	x13, #19\n\t"
        "extr	x12, x12, x9, #63\n\t"
        "mul	x12, x12, x13\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x11", "x12", "x13", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10"
    );
}

void fe_sq2(fe r, const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-16]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Square * 2 */
        "ldp	x2, x3, [x1]\n\t"
        "ldp	x4, x5, [x1, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x7, x2, x3\n\t"
        "umulh	x8, x2, x3\n\t"
        /*  A[0] * A[2] */
        "mul	x11, x2, x4\n\t"
        "umulh	x9, x2, x4\n\t"
        "adds	x8, x8, x11\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x11, x2, x5\n\t"
        "umulh	x10, x2, x5\n\t"
        "adds	x9, x9, x11\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x11, x3, x4\n\t"
        "umulh	x12, x3, x4\n\t"
        "adds	x9, x9, x11\n\t"
        "adcs	x10, x10, x12\n\t"
        "adc	x14, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x11, x3, x5\n\t"
        "umulh	x12, x3, x5\n\t"
        "adds	x10, x10, x11\n\t"
        "adc	x14, x14, x12\n\t"
        /*  A[2] * A[3] */
        "mul	x11, x4, x5\n\t"
        "umulh	x15, x4, x5\n\t"
        "adds	x14, x14, x11\n\t"
        "adc	x15, x15, xzr\n\t"
        /* Double */
        "adds	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adcs	x14, x14, x14\n\t"
        "adcs	x15, x15, x15\n\t"
        "adc	x16, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x6, x2, x2\n\t"
        "umulh	x17, x2, x2\n\t"
        /*  A[1] * A[1] */
        "mul	x11, x3, x3\n\t"
        "umulh	x12, x3, x3\n\t"
        "adds	x7, x7, x17\n\t"
        "adcs	x8, x8, x11\n\t"
        "adc	x17, x12, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x11, x4, x4\n\t"
        "umulh	x12, x4, x4\n\t"
        "adds	x9, x9, x17\n\t"
        "adcs	x10, x10, x11\n\t"
        "adc	x17, x12, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x11, x5, x5\n\t"
        "umulh	x12, x5, x5\n\t"
        "adds	x14, x14, x17\n\t"
        "adcs	x15, x15, x11\n\t"
        "adc	x16, x16, x12\n\t"
        /* Double and Reduce */
        "mov	x11, #0x169\n\t"
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "lsr	x17, x16, #61\n\t"
        "extr	x16, x16, x15, #62\n\t"
        "extr	x15, x15, x14, #62\n\t"
        "extr	x14, x14, x10, #62\n\t"
        "extr	x10, x10, x9, #62\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "lsl	x6, x6, #1\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Two left, only one right */
        "and	x16, x16, #0x7fffffffffffffff\n\t"
        /*  Multiply top bits by 19*19 */
        "mul	x17, x17, x11\n\t"
        /*  Multiply top half by 19 */
        "mov	x11, #19\n\t"
        "mul	x12, x11, x10\n\t"
        "umulh	x10, x11, x10\n\t"
        "adds	x6, x6, x12\n\t"
        "mul	x12, x11, x14\n\t"
        "umulh	x14, x11, x14\n\t"
        "adcs	x7, x7, x12\n\t"
        "mul	x12, x11, x15\n\t"
        "umulh	x15, x11, x15\n\t"
        "adcs	x8, x8, x12\n\t"
        "mul	x12, x11, x16\n\t"
        "umulh	x13, x11, x16\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x6, x6, x17\n\t"
        "adcs	x7, x7, x10\n\t"
        "adcs	x8, x8, x14\n\t"
        "adcs	x9, x9, x15\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  Overflow */
        "extr	x13, x13, x9, #63\n\t"
        "mul	x13, x13, x11\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x13\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x13, x9, #63\n\t"
        "mul	x13, x13, x11\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x13\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #16\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x11", "x12", "x13", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x14", "x15", "x16", "x17", "x18"
    );
}

void fe_invert(fe r, const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-160]!\n\t"
        "add	x29, sp, #0\n\t"
        /* Invert */
        "str	%[r], [x29, #144]\n\t"
        "str	%[a], [x29, #152]\n\t"
        "add	x0, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "add	x1, x29, #48\n\t"
        "bl	fe_sq\n\t"
        "ldr	x1, [x29, #152]\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #16\n\t"
        "add	x1, x29, #16\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #48\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "mov	x20, #4\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_invert1:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert1\n\t"
        "add	x0, x29, #48\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #80\n\t"
        "add	x1, x29, #48\n\t"
        "bl	fe_sq\n\t"
        "mov	x20, #9\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_invert2:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert2\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #112\n\t"
        "bl	fe_sq\n\t"
        "mov	x20, #19\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_fe_invert3:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert3\n\t"
        "add	x0, x29, #80\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "mov	x20, #10\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_invert4:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert4\n\t"
        "add	x0, x29, #48\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #80\n\t"
        "add	x1, x29, #48\n\t"
        "bl	fe_sq\n\t"
        "mov	x20, #49\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_invert5:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert5\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #112\n\t"
        "bl	fe_sq\n\t"
        "mov	x20, #0x63\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_fe_invert6:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert6\n\t"
        "add	x0, x29, #80\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "mov	x20, #50\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_invert7:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert7\n\t"
        "add	x0, x29, #48\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "mov	x20, #5\n\t"
        "add	x1, x29, #48\n\t"
        "\n"
    "L_fe_invert8:\n\t"
        "bl	fe_sq\n\t"
        "sub	x20, x20, #1\n\t"
        "cmp	x20, #0\n\t"
        "bne	L_fe_invert8\n\t"
        "ldr	x0, [x29, #144]\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "ldr	%[a], [x29, #152]\n\t"
        "ldr	%[r], [x29, #144]\n\t"
        "ldp	x29, x30, [sp], #0xa0\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x20"
    );
}

int curve25519(byte* r, byte* n, byte* a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-192]!\n\t"
        "add	x29, sp, #0\n\t"
        "mov	x22, xzr\n\t"
        "str	%[r], [x29, #176]\n\t"
        /* Set one */
        "mov	x23, #1\n\t"
        "stp	x23, xzr, [x0]\n\t"
        "stp	xzr, xzr, [x0, #16]\n\t"
        /* Set zero */
        "stp	xzr, xzr, [x29, #16]\n\t"
        "stp	xzr, xzr, [x29, #32]\n\t"
        /* Set one */
        "mov	x23, #1\n\t"
        "stp	x23, xzr, [x29, #48]\n\t"
        "stp	xzr, xzr, [x29, #64]\n\t"
        /* Copy */
        "ldp	x6, x7, [x2]\n\t"
        "ldp	x8, x9, [x2, #16]\n\t"
        "stp	x6, x7, [x29, #80]\n\t"
        "stp	x8, x9, [x29, #96]\n\t"
        "mov	x25, #62\n\t"
        "mov	x24, #24\n\t"
        "\n"
    "L_curve25519_words:\n\t"
        "\n"
    "L_curve25519_bits:\n\t"
        "ldr	x23, [x1, x24]\n\t"
        "lsr	x23, x23, x25\n\t"
        "and	x23, x23, #1\n\t"
        "eor	x22, x22, x23\n\t"
        /* Conditional Swap */
        "cmp	x22, #1\n\t"
        "ldp	x6, x7, [x0]\n\t"
        "ldp	x8, x9, [x0, #16]\n\t"
        "ldp	x10, x11, [x29, #80]\n\t"
        "ldp	x12, x13, [x29, #96]\n\t"
        "csel	x14, x6, x10, eq\n\t"
        "csel	x6, x10, x6, eq\n\t"
        "csel	x15, x7, x11, eq\n\t"
        "csel	x7, x11, x7, eq\n\t"
        "csel	x16, x8, x12, eq\n\t"
        "csel	x8, x12, x8, eq\n\t"
        "csel	x17, x9, x13, eq\n\t"
        "csel	x9, x13, x9, eq\n\t"
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        "stp	x14, x15, [x29, #80]\n\t"
        "stp	x16, x17, [x29, #96]\n\t"
        /* Conditional Swap */
        "cmp	x22, #1\n\t"
        "ldp	x6, x7, [x29, #16]\n\t"
        "ldp	x8, x9, [x29, #32]\n\t"
        "ldp	x10, x11, [x29, #48]\n\t"
        "ldp	x12, x13, [x29, #64]\n\t"
        "csel	x14, x6, x10, eq\n\t"
        "csel	x6, x10, x6, eq\n\t"
        "csel	x15, x7, x11, eq\n\t"
        "csel	x7, x11, x7, eq\n\t"
        "csel	x16, x8, x12, eq\n\t"
        "csel	x8, x12, x8, eq\n\t"
        "csel	x17, x9, x13, eq\n\t"
        "csel	x9, x13, x9, eq\n\t"
        "stp	x6, x7, [x29, #16]\n\t"
        "stp	x8, x9, [x29, #32]\n\t"
        "stp	x14, x15, [x29, #48]\n\t"
        "stp	x16, x17, [x29, #64]\n\t"
        "mov	x22, x23\n\t"
        /* Add */
        "ldp	x6, x7, [x0]\n\t"
        "ldp	x8, x9, [x0, #16]\n\t"
        "ldp	x10, x11, [x29, #16]\n\t"
        "ldp	x12, x13, [x29, #32]\n\t"
        "adds	x14, x6, x10\n\t"
        "adcs	x15, x7, x11\n\t"
        "adcs	x16, x8, x12\n\t"
        "adc	x17, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "asr	x23, x17, #63\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x14, x14, x3\n\t"
        "sbcs	x15, x15, x23\n\t"
        "sbcs	x16, x16, x23\n\t"
        "sbc	x17, x17, x4\n\t"
        /* Sub */
        "subs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "sbcs	x8, x8, x12\n\t"
        "sbcs	x9, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "csetm	x23, cc\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x6, x6, x3\n\t"
        "adcs	x7, x7, x23\n\t"
        "adcs	x8, x8, x23\n\t"
        "adc	x9, x9, x4\n\t"
        "stp	x14, x15, [x0]\n\t"
        "stp	x16, x17, [x0, #16]\n\t"
        "stp	x6, x7, [x29, #144]\n\t"
        "stp	x8, x9, [x29, #160]\n\t"
        /* Add */
        "ldp	x6, x7, [x29, #80]\n\t"
        "ldp	x8, x9, [x29, #96]\n\t"
        "ldp	x10, x11, [x29, #48]\n\t"
        "ldp	x12, x13, [x29, #64]\n\t"
        "adds	x14, x6, x10\n\t"
        "adcs	x15, x7, x11\n\t"
        "adcs	x16, x8, x12\n\t"
        "adc	x17, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "asr	x23, x17, #63\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x14, x14, x3\n\t"
        "sbcs	x15, x15, x23\n\t"
        "sbcs	x16, x16, x23\n\t"
        "sbc	x17, x17, x4\n\t"
        /* Sub */
        "subs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "sbcs	x8, x8, x12\n\t"
        "sbcs	x9, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "csetm	x23, cc\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x6, x6, x3\n\t"
        "adcs	x7, x7, x23\n\t"
        "adcs	x8, x8, x23\n\t"
        "adc	x9, x9, x4\n\t"
        "stp	x14, x15, [x29, #16]\n\t"
        "stp	x16, x17, [x29, #32]\n\t"
        "stp	x6, x7, [x29, #112]\n\t"
        "stp	x8, x9, [x29, #128]\n\t"
        /* Multiply */
        "ldp	x18, x19, [x29, #112]\n\t"
        "ldp	x20, x21, [x29, #128]\n\t"
        "ldp	x14, x15, [x0]\n\t"
        "ldp	x16, x17, [x0, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x18, x14\n\t"
        "umulh	x7, x18, x14\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x18, x15\n\t"
        "umulh	x8, x18, x15\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x19, x14\n\t"
        "umulh	x4, x19, x14\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x18, x16\n\t"
        "umulh	x4, x18, x16\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x19, x15\n\t"
        "umulh	x4, x19, x15\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x20, x14\n\t"
        "umulh	x4, x20, x14\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x18, x17\n\t"
        "umulh	x4, x18, x17\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x19, x16\n\t"
        "umulh	x4, x19, x16\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x20, x15\n\t"
        "umulh	x4, x20, x15\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x21, x14\n\t"
        "umulh	x4, x21, x14\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x19, x17\n\t"
        "umulh	x4, x19, x17\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x20, x16\n\t"
        "umulh	x4, x20, x16\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x21, x15\n\t"
        "umulh	x4, x21, x15\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x20, x17\n\t"
        "umulh	x4, x20, x17\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x21, x16\n\t"
        "umulh	x4, x21, x16\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x21, x17\n\t"
        "umulh	x4, x21, x17\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #48]\n\t"
        "stp	x8, x9, [x29, #64]\n\t"
        /* Multiply */
        "ldp	x18, x19, [x29, #16]\n\t"
        "ldp	x20, x21, [x29, #32]\n\t"
        "ldp	x14, x15, [x29, #144]\n\t"
        "ldp	x16, x17, [x29, #160]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x18, x14\n\t"
        "umulh	x7, x18, x14\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x18, x15\n\t"
        "umulh	x8, x18, x15\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x19, x14\n\t"
        "umulh	x4, x19, x14\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x18, x16\n\t"
        "umulh	x4, x18, x16\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x19, x15\n\t"
        "umulh	x4, x19, x15\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x20, x14\n\t"
        "umulh	x4, x20, x14\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x18, x17\n\t"
        "umulh	x4, x18, x17\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x19, x16\n\t"
        "umulh	x4, x19, x16\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x20, x15\n\t"
        "umulh	x4, x20, x15\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x21, x14\n\t"
        "umulh	x4, x21, x14\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x19, x17\n\t"
        "umulh	x4, x19, x17\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x20, x16\n\t"
        "umulh	x4, x20, x16\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x21, x15\n\t"
        "umulh	x4, x21, x15\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x20, x17\n\t"
        "umulh	x4, x20, x17\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x21, x16\n\t"
        "umulh	x4, x21, x16\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x21, x17\n\t"
        "umulh	x4, x21, x17\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #16]\n\t"
        "stp	x8, x9, [x29, #32]\n\t"
        /* Square */
        "ldp	x18, x19, [x29, #144]\n\t"
        "ldp	x20, x21, [x29, #160]\n\t"
        /*  A[0] * A[1] */
        "mul	x7, x18, x19\n\t"
        "umulh	x8, x18, x19\n\t"
        /*  A[0] * A[2] */
        "mul	x3, x18, x20\n\t"
        "umulh	x9, x18, x20\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x3, x18, x21\n\t"
        "umulh	x10, x18, x21\n\t"
        "adds	x9, x9, x3\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x3, x19, x20\n\t"
        "umulh	x4, x19, x20\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x3, x19, x21\n\t"
        "umulh	x4, x19, x21\n\t"
        "adds	x10, x10, x3\n\t"
        "adc	x11, x11, x4\n\t"
        /*  A[2] * A[3] */
        "mul	x3, x20, x21\n\t"
        "umulh	x12, x20, x21\n\t"
        "adds	x11, x11, x3\n\t"
        "adc	x12, x12, xzr\n\t"
        /* Double */
        "adds	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adcs	x11, x11, x11\n\t"
        "adcs	x12, x12, x12\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x6, x18, x18\n\t"
        "umulh	x23, x18, x18\n\t"
        /*  A[1] * A[1] */
        "mul	x3, x19, x19\n\t"
        "umulh	x4, x19, x19\n\t"
        "adds	x7, x7, x23\n\t"
        "adcs	x8, x8, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x3, x20, x20\n\t"
        "umulh	x4, x20, x20\n\t"
        "adds	x9, x9, x23\n\t"
        "adcs	x10, x10, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x3, x21, x21\n\t"
        "umulh	x4, x21, x21\n\t"
        "adds	x11, x11, x23\n\t"
        "adcs	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #112]\n\t"
        "stp	x8, x9, [x29, #128]\n\t"
        /* Square */
        "ldp	x18, x19, [x0]\n\t"
        "ldp	x20, x21, [x0, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x7, x18, x19\n\t"
        "umulh	x8, x18, x19\n\t"
        /*  A[0] * A[2] */
        "mul	x3, x18, x20\n\t"
        "umulh	x9, x18, x20\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x3, x18, x21\n\t"
        "umulh	x10, x18, x21\n\t"
        "adds	x9, x9, x3\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x3, x19, x20\n\t"
        "umulh	x4, x19, x20\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x3, x19, x21\n\t"
        "umulh	x4, x19, x21\n\t"
        "adds	x10, x10, x3\n\t"
        "adc	x11, x11, x4\n\t"
        /*  A[2] * A[3] */
        "mul	x3, x20, x21\n\t"
        "umulh	x12, x20, x21\n\t"
        "adds	x11, x11, x3\n\t"
        "adc	x12, x12, xzr\n\t"
        /* Double */
        "adds	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adcs	x11, x11, x11\n\t"
        "adcs	x12, x12, x12\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x6, x18, x18\n\t"
        "umulh	x23, x18, x18\n\t"
        /*  A[1] * A[1] */
        "mul	x3, x19, x19\n\t"
        "umulh	x4, x19, x19\n\t"
        "adds	x7, x7, x23\n\t"
        "adcs	x8, x8, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x3, x20, x20\n\t"
        "umulh	x4, x20, x20\n\t"
        "adds	x9, x9, x23\n\t"
        "adcs	x10, x10, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x3, x21, x21\n\t"
        "umulh	x4, x21, x21\n\t"
        "adds	x11, x11, x23\n\t"
        "adcs	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #144]\n\t"
        "stp	x8, x9, [x29, #160]\n\t"
        /* Add */
        "ldp	x6, x7, [x29, #48]\n\t"
        "ldp	x8, x9, [x29, #64]\n\t"
        "ldp	x10, x11, [x29, #16]\n\t"
        "ldp	x12, x13, [x29, #32]\n\t"
        "adds	x14, x6, x10\n\t"
        "adcs	x15, x7, x11\n\t"
        "adcs	x16, x8, x12\n\t"
        "adc	x17, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "asr	x23, x17, #63\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x14, x14, x3\n\t"
        "sbcs	x15, x15, x23\n\t"
        "sbcs	x16, x16, x23\n\t"
        "sbc	x17, x17, x4\n\t"
        /* Sub */
        "subs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "sbcs	x8, x8, x12\n\t"
        "sbcs	x9, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "csetm	x23, cc\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x6, x6, x3\n\t"
        "adcs	x7, x7, x23\n\t"
        "adcs	x8, x8, x23\n\t"
        "adc	x9, x9, x4\n\t"
        "stp	x14, x15, [x29, #80]\n\t"
        "stp	x16, x17, [x29, #96]\n\t"
        "stp	x6, x7, [x29, #16]\n\t"
        "stp	x8, x9, [x29, #32]\n\t"
        /* Multiply */
        "ldp	x18, x19, [x29, #144]\n\t"
        "ldp	x20, x21, [x29, #160]\n\t"
        "ldp	x14, x15, [x29, #112]\n\t"
        "ldp	x16, x17, [x29, #128]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x18, x14\n\t"
        "umulh	x7, x18, x14\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x18, x15\n\t"
        "umulh	x8, x18, x15\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x19, x14\n\t"
        "umulh	x4, x19, x14\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x18, x16\n\t"
        "umulh	x4, x18, x16\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x19, x15\n\t"
        "umulh	x4, x19, x15\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x20, x14\n\t"
        "umulh	x4, x20, x14\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x18, x17\n\t"
        "umulh	x4, x18, x17\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x19, x16\n\t"
        "umulh	x4, x19, x16\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x20, x15\n\t"
        "umulh	x4, x20, x15\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x21, x14\n\t"
        "umulh	x4, x21, x14\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x19, x17\n\t"
        "umulh	x4, x19, x17\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x20, x16\n\t"
        "umulh	x4, x20, x16\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x21, x15\n\t"
        "umulh	x4, x21, x15\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x20, x17\n\t"
        "umulh	x4, x20, x17\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x21, x16\n\t"
        "umulh	x4, x21, x16\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x21, x17\n\t"
        "umulh	x4, x21, x17\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        /* Sub */
        "ldp	x6, x7, [x29, #144]\n\t"
        "ldp	x8, x9, [x29, #160]\n\t"
        "ldp	x10, x11, [x29, #112]\n\t"
        "ldp	x12, x13, [x29, #128]\n\t"
        "subs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "sbcs	x8, x8, x12\n\t"
        "sbcs	x9, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "csetm	x23, cc\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x6, x6, x3\n\t"
        "adcs	x7, x7, x23\n\t"
        "adcs	x8, x8, x23\n\t"
        "adc	x9, x9, x4\n\t"
        "stp	x6, x7, [x29, #144]\n\t"
        "stp	x8, x9, [x29, #160]\n\t"
        /* Square */
        "ldp	x18, x19, [x29, #16]\n\t"
        "ldp	x20, x21, [x29, #32]\n\t"
        /*  A[0] * A[1] */
        "mul	x7, x18, x19\n\t"
        "umulh	x8, x18, x19\n\t"
        /*  A[0] * A[2] */
        "mul	x3, x18, x20\n\t"
        "umulh	x9, x18, x20\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x3, x18, x21\n\t"
        "umulh	x10, x18, x21\n\t"
        "adds	x9, x9, x3\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x3, x19, x20\n\t"
        "umulh	x4, x19, x20\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x3, x19, x21\n\t"
        "umulh	x4, x19, x21\n\t"
        "adds	x10, x10, x3\n\t"
        "adc	x11, x11, x4\n\t"
        /*  A[2] * A[3] */
        "mul	x3, x20, x21\n\t"
        "umulh	x12, x20, x21\n\t"
        "adds	x11, x11, x3\n\t"
        "adc	x12, x12, xzr\n\t"
        /* Double */
        "adds	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adcs	x11, x11, x11\n\t"
        "adcs	x12, x12, x12\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x6, x18, x18\n\t"
        "umulh	x23, x18, x18\n\t"
        /*  A[1] * A[1] */
        "mul	x3, x19, x19\n\t"
        "umulh	x4, x19, x19\n\t"
        "adds	x7, x7, x23\n\t"
        "adcs	x8, x8, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x3, x20, x20\n\t"
        "umulh	x4, x20, x20\n\t"
        "adds	x9, x9, x23\n\t"
        "adcs	x10, x10, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x3, x21, x21\n\t"
        "umulh	x4, x21, x21\n\t"
        "adds	x11, x11, x23\n\t"
        "adcs	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #16]\n\t"
        "stp	x8, x9, [x29, #32]\n\t"
        /* Multiply by 121666 */
        "ldp	x18, x19, [x29, #144]\n\t"
        "ldp	x20, x21, [x29, #160]\n\t"
        "mov	x5, #0xdb42\n\t"
        "movk	x5, #1, lsl 16\n\t"
        "mul	x6, x18, x5\n\t"
        "umulh	x7, x18, x5\n\t"
        "mul	x3, x19, x5\n\t"
        "umulh	x4, x19, x5\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, xzr, x4\n\t"
        "mul	x3, x20, x5\n\t"
        "umulh	x4, x20, x5\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, xzr, x4\n\t"
        "mul	x3, x21, x5\n\t"
        "umulh	x4, x21, x5\n\t"
        "adds	x9, x9, x3\n\t"
        "adc	x4, xzr, x4\n\t"
        "mov	x5, #19\n\t"
        "extr	x4, x4, x9, #63\n\t"
        "mul	x4, x4, x5\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x4\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        "stp	x6, x7, [x29, #48]\n\t"
        "stp	x8, x9, [x29, #64]\n\t"
        /* Square */
        "ldp	x18, x19, [x29, #80]\n\t"
        "ldp	x20, x21, [x29, #96]\n\t"
        /*  A[0] * A[1] */
        "mul	x7, x18, x19\n\t"
        "umulh	x8, x18, x19\n\t"
        /*  A[0] * A[2] */
        "mul	x3, x18, x20\n\t"
        "umulh	x9, x18, x20\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x3, x18, x21\n\t"
        "umulh	x10, x18, x21\n\t"
        "adds	x9, x9, x3\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x3, x19, x20\n\t"
        "umulh	x4, x19, x20\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x3, x19, x21\n\t"
        "umulh	x4, x19, x21\n\t"
        "adds	x10, x10, x3\n\t"
        "adc	x11, x11, x4\n\t"
        /*  A[2] * A[3] */
        "mul	x3, x20, x21\n\t"
        "umulh	x12, x20, x21\n\t"
        "adds	x11, x11, x3\n\t"
        "adc	x12, x12, xzr\n\t"
        /* Double */
        "adds	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adcs	x11, x11, x11\n\t"
        "adcs	x12, x12, x12\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x6, x18, x18\n\t"
        "umulh	x23, x18, x18\n\t"
        /*  A[1] * A[1] */
        "mul	x3, x19, x19\n\t"
        "umulh	x4, x19, x19\n\t"
        "adds	x7, x7, x23\n\t"
        "adcs	x8, x8, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x3, x20, x20\n\t"
        "umulh	x4, x20, x20\n\t"
        "adds	x9, x9, x23\n\t"
        "adcs	x10, x10, x3\n\t"
        "adc	x23, x4, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x3, x21, x21\n\t"
        "umulh	x4, x21, x21\n\t"
        "adds	x11, x11, x23\n\t"
        "adcs	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #80]\n\t"
        "stp	x8, x9, [x29, #96]\n\t"
        /* Add */
        "ldp	x6, x7, [x29, #112]\n\t"
        "ldp	x8, x9, [x29, #128]\n\t"
        "ldp	x10, x11, [x29, #48]\n\t"
        "ldp	x12, x13, [x29, #64]\n\t"
        "adds	x6, x6, x10\n\t"
        "adcs	x7, x7, x11\n\t"
        "adcs	x8, x8, x12\n\t"
        "adc	x9, x9, x13\n\t"
        "mov	x3, #-19\n\t"
        "asr	x23, x9, #63\n\t"
        /*   Mask the modulus */
        "and	x3, x23, x3\n\t"
        "and	x4, x23, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x6, x6, x3\n\t"
        "sbcs	x7, x7, x23\n\t"
        "sbcs	x8, x8, x23\n\t"
        "sbc	x9, x9, x4\n\t"
        "stp	x6, x7, [x29, #112]\n\t"
        "stp	x8, x9, [x29, #128]\n\t"
        /* Multiply */
        "ldp	x18, x19, [x2]\n\t"
        "ldp	x20, x21, [x2, #16]\n\t"
        "ldp	x14, x15, [x29, #16]\n\t"
        "ldp	x16, x17, [x29, #32]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x18, x14\n\t"
        "umulh	x7, x18, x14\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x18, x15\n\t"
        "umulh	x8, x18, x15\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x19, x14\n\t"
        "umulh	x4, x19, x14\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x18, x16\n\t"
        "umulh	x4, x18, x16\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x19, x15\n\t"
        "umulh	x4, x19, x15\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x20, x14\n\t"
        "umulh	x4, x20, x14\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x18, x17\n\t"
        "umulh	x4, x18, x17\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x19, x16\n\t"
        "umulh	x4, x19, x16\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x20, x15\n\t"
        "umulh	x4, x20, x15\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x21, x14\n\t"
        "umulh	x4, x21, x14\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x19, x17\n\t"
        "umulh	x4, x19, x17\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x20, x16\n\t"
        "umulh	x4, x20, x16\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x21, x15\n\t"
        "umulh	x4, x21, x15\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x20, x17\n\t"
        "umulh	x4, x20, x17\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x21, x16\n\t"
        "umulh	x4, x21, x16\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x21, x17\n\t"
        "umulh	x4, x21, x17\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #48]\n\t"
        "stp	x8, x9, [x29, #64]\n\t"
        /* Multiply */
        "ldp	x18, x19, [x29, #144]\n\t"
        "ldp	x20, x21, [x29, #160]\n\t"
        "ldp	x14, x15, [x29, #112]\n\t"
        "ldp	x16, x17, [x29, #128]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x18, x14\n\t"
        "umulh	x7, x18, x14\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x18, x15\n\t"
        "umulh	x8, x18, x15\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x19, x14\n\t"
        "umulh	x4, x19, x14\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x18, x16\n\t"
        "umulh	x4, x18, x16\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x19, x15\n\t"
        "umulh	x4, x19, x15\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x20, x14\n\t"
        "umulh	x4, x20, x14\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x18, x17\n\t"
        "umulh	x4, x18, x17\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x19, x16\n\t"
        "umulh	x4, x19, x16\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x20, x15\n\t"
        "umulh	x4, x20, x15\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x21, x14\n\t"
        "umulh	x4, x21, x14\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x19, x17\n\t"
        "umulh	x4, x19, x17\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x20, x16\n\t"
        "umulh	x4, x20, x16\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x21, x15\n\t"
        "umulh	x4, x21, x15\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x20, x17\n\t"
        "umulh	x4, x20, x17\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x21, x16\n\t"
        "umulh	x4, x21, x16\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x21, x17\n\t"
        "umulh	x4, x21, x17\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x29, #16]\n\t"
        "stp	x8, x9, [x29, #32]\n\t"
        "sub	x25, x25, #1\n\t"
        "cmp	x25, #0\n\t"
        "bge	L_curve25519_bits\n\t"
        "mov	x25, #63\n\t"
        "sub	x24, x24, #8\n\t"
        "cmp	x24, #0\n\t"
        "bge	L_curve25519_words\n\t"
        /* Invert */
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "add	x0, x29, #80\n\t"
        "add	x1, x29, #48\n\t"
        "bl	fe_sq\n\t"
        "add	x1, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "add	x1, x29, #16\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #48\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #112\n\t"
        "bl	fe_sq\n\t"
        "add	x0, x29, #80\n\t"
        "add	x1, x29, #80\n\t"
        "add	x2, x29, #112\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #112\n\t"
        "bl	fe_sq\n\t"
        "mov	x24, #4\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_curve25519_inv_1:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_1\n\t"
        "add	x0, x29, #80\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #112\n\t"
        "add	x1, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "mov	x24, #9\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_curve25519_inv_2:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_2\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #144\n\t"
        "bl	fe_sq\n\t"
        "mov	x24, #19\n\t"
        "add	x1, x29, #144\n\t"
        "\n"
    "L_curve25519_inv_3:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_3\n\t"
        "add	x0, x29, #112\n\t"
        "add	x2, x29, #112\n\t"
        "bl	fe_mul\n\t"
        "mov	x24, #10\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_curve25519_inv_4:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_4\n\t"
        "add	x0, x29, #80\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #112\n\t"
        "add	x1, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "mov	x24, #49\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_curve25519_inv_5:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_5\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #144\n\t"
        "bl	fe_sq\n\t"
        "mov	x24, #0x63\n\t"
        "add	x1, x29, #144\n\t"
        "\n"
    "L_curve25519_inv_6:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_6\n\t"
        "add	x0, x29, #112\n\t"
        "add	x2, x29, #112\n\t"
        "bl	fe_mul\n\t"
        "mov	x24, #50\n\t"
        "add	x1, x29, #112\n\t"
        "\n"
    "L_curve25519_inv_7:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_7\n\t"
        "add	x0, x29, #80\n\t"
        "add	x2, x29, #80\n\t"
        "bl	fe_mul\n\t"
        "mov	x24, #5\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_curve25519_inv_8:\n\t"
        "bl	fe_sq\n\t"
        "sub	x24, x24, #1\n\t"
        "cmp	x24, #0\n\t"
        "bne	L_curve25519_inv_8\n\t"
        "add	x0, x29, #16\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "ldr	%[r], [x29, #176]\n\t"
        /* Multiply */
        "ldp	x18, x19, [x0]\n\t"
        "ldp	x20, x21, [x0, #16]\n\t"
        "ldp	x14, x15, [x29, #16]\n\t"
        "ldp	x16, x17, [x29, #32]\n\t"
        /*  A[0] * B[0] */
        "mul	x6, x18, x14\n\t"
        "umulh	x7, x18, x14\n\t"
        /*  A[0] * B[1] */
        "mul	x3, x18, x15\n\t"
        "umulh	x8, x18, x15\n\t"
        "adds	x7, x7, x3\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x3, x19, x14\n\t"
        "umulh	x4, x19, x14\n\t"
        "adds	x7, x7, x3\n\t"
        "adcs	x8, x8, x4\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x3, x18, x16\n\t"
        "umulh	x4, x18, x16\n\t"
        "adds	x8, x8, x3\n\t"
        "adc	x9, x9, x4\n\t"
        /*  A[1] * B[1] */
        "mul	x3, x19, x15\n\t"
        "umulh	x4, x19, x15\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x3, x20, x14\n\t"
        "umulh	x4, x20, x14\n\t"
        "adds	x8, x8, x3\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x3, x18, x17\n\t"
        "umulh	x4, x18, x17\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x3, x19, x16\n\t"
        "umulh	x4, x19, x16\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x3, x20, x15\n\t"
        "umulh	x4, x20, x15\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x3, x21, x14\n\t"
        "umulh	x4, x21, x14\n\t"
        "adds	x9, x9, x3\n\t"
        "adcs	x10, x10, x4\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x3, x19, x17\n\t"
        "umulh	x4, x19, x17\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x3, x20, x16\n\t"
        "umulh	x4, x20, x16\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x3, x21, x15\n\t"
        "umulh	x4, x21, x15\n\t"
        "adds	x10, x10, x3\n\t"
        "adcs	x11, x11, x4\n\t"
        "adc	x12, x12, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x3, x20, x17\n\t"
        "umulh	x4, x20, x17\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x3, x21, x16\n\t"
        "umulh	x4, x21, x16\n\t"
        "adds	x11, x11, x3\n\t"
        "adcs	x12, x12, x4\n\t"
        "adc	x13, x13, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x3, x21, x17\n\t"
        "umulh	x4, x21, x17\n\t"
        "adds	x12, x12, x3\n\t"
        "adc	x13, x13, x4\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x13, x13, x12, #63\n\t"
        "extr	x12, x12, x11, #63\n\t"
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x3, #19\n\t"
        "mul	x4, x3, x10\n\t"
        "umulh	x10, x3, x10\n\t"
        "adds	x6, x6, x4\n\t"
        "mul	x4, x3, x11\n\t"
        "umulh	x11, x3, x11\n\t"
        "adcs	x7, x7, x4\n\t"
        "mul	x4, x3, x12\n\t"
        "umulh	x12, x3, x12\n\t"
        "adcs	x8, x8, x4\n\t"
        "mul	x4, x3, x13\n\t"
        "umulh	x5, x3, x13\n\t"
        "adcs	x9, x9, x4\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x7, x7, x10\n\t"
        "adcs	x8, x8, x11\n\t"
        "adcs	x9, x9, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  Overflow */
        "extr	x5, x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x5, x9, #63\n\t"
        "mul	x5, x5, x3\n\t"
        "and	x9, x9, #0x7fffffffffffffff\n\t"
        "adds	x6, x6, x5\n\t"
        "adcs	x7, x7, xzr\n\t"
        "adcs	x8, x8, xzr\n\t"
        "adc	x9, x9, xzr\n\t"
        /* Store */
        "stp	x6, x7, [x0]\n\t"
        "stp	x8, x9, [x0, #16]\n\t"
        "mov	x0, xzr\n\t"
        "ldp	x29, x30, [sp], #0xc0\n\t"
        : [r] "+r" (r), [n] "+r" (n), [a] "+r" (a)
        :
        : "memory", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10", "x11", "x12", "x13", "x14", "x15", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23", "x24", "x25"
    );
    return (uint32_t)(size_t)r;
}

void fe_pow22523(fe r, const fe a)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-128]!\n\t"
        "add	x29, sp, #0\n\t"
        /* pow22523 */
        "str	%[r], [x29, #112]\n\t"
        "str	%[a], [x29, #120]\n\t"
        "add	x0, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "add	x1, x29, #48\n\t"
        "bl	fe_sq\n\t"
        "ldr	x1, [x29, #120]\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #16\n\t"
        "add	x1, x29, #16\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "bl	fe_sq\n\t"
        "add	x1, x29, #48\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "mov	x21, #4\n\t"
        "add	x1, x29, #48\n\t"
        "\n"
    "L_fe_pow22523_1:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_1\n\t"
        "add	x0, x29, #16\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "mov	x21, #9\n\t"
        "add	x1, x29, #48\n\t"
        "\n"
    "L_fe_pow22523_2:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_2\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "mov	x21, #19\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_pow22523_3:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_3\n\t"
        "add	x0, x29, #48\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "mov	x21, #10\n\t"
        "add	x1, x29, #48\n\t"
        "\n"
    "L_fe_pow22523_4:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_4\n\t"
        "add	x0, x29, #16\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #48\n\t"
        "add	x1, x29, #16\n\t"
        "bl	fe_sq\n\t"
        "mov	x21, #49\n\t"
        "add	x1, x29, #48\n\t"
        "\n"
    "L_fe_pow22523_5:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_5\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "add	x0, x29, #80\n\t"
        "bl	fe_sq\n\t"
        "mov	x21, #0x63\n\t"
        "add	x1, x29, #80\n\t"
        "\n"
    "L_fe_pow22523_6:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_6\n\t"
        "add	x0, x29, #48\n\t"
        "add	x2, x29, #48\n\t"
        "bl	fe_mul\n\t"
        "mov	x21, #50\n\t"
        "add	x1, x29, #48\n\t"
        "\n"
    "L_fe_pow22523_7:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_7\n\t"
        "add	x0, x29, #16\n\t"
        "add	x2, x29, #16\n\t"
        "bl	fe_mul\n\t"
        "mov	x21, #2\n\t"
        "add	x1, x29, #16\n\t"
        "\n"
    "L_fe_pow22523_8:\n\t"
        "bl	fe_sq\n\t"
        "sub	x21, x21, #1\n\t"
        "cmp	x21, #0\n\t"
        "bne	L_fe_pow22523_8\n\t"
        "ldr	x0, [x29, #112]\n\t"
        "ldr	x2, [x29, #120]\n\t"
        "bl	fe_mul\n\t"
        "ldr	%[a], [x29, #120]\n\t"
        "ldr	%[r], [x29, #112]\n\t"
        "ldp	x29, x30, [sp], #0x80\n\t"
        : [r] "+r" (r), [a] "+r" (a)
        :
        : "memory", "x21"
    );
}

void fe_ge_to_p2(fe rx, fe ry, fe rz, const fe px, const fe py, const fe pz, const fe pt)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-64]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[ry], [x29, #16]\n\t"
        "str	%[rz], [x29, #24]\n\t"
        "str	%[px], [x29, #32]\n\t"
        "str	%[py], [x29, #40]\n\t"
        "str	%[pz], [x29, #48]\n\t"
        "str	%[pt], [x29, #56]\n\t"
        "ldr	x1, [x29, #32]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x1]\n\t"
        "ldp	x17, x18, [x1, #16]\n\t"
        "ldp	x19, x20, [x2]\n\t"
        "ldp	x21, x22, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldr	x0, [x29, #16]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        "ldr	x2, [x29, #48]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x1]\n\t"
        "ldp	x17, x18, [x1, #16]\n\t"
        "ldp	x19, x20, [x2]\n\t"
        "ldp	x21, x22, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldr	x0, [x29, #24]\n\t"
        "ldr	x1, [x29, #56]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x2]\n\t"
        "ldp	x17, x18, [x2, #16]\n\t"
        "ldp	x19, x20, [x1]\n\t"
        "ldp	x21, x22, [x1, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #0x40\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz), [pt] "+r" (pt)
        :
        : "memory", "x12", "x13", "x14", "x15", "x7", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22"
    );
}

void fe_ge_to_p3(fe rx, fe ry, fe rz, fe rt, const fe px, const fe py, const fe pz, const fe pt)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-80]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[ry], [x29, #16]\n\t"
        "str	%[rz], [x29, #24]\n\t"
        "str	%[rt], [x29, #32]\n\t"
        "str	%[px], [x29, #40]\n\t"
        "str	%[py], [x29, #48]\n\t"
        "str	%[pz], [x29, #56]\n\t"
        "str	%[pt], [x29, #64]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        "ldr	x2, [x29, #64]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x1]\n\t"
        "ldp	x17, x18, [x1, #16]\n\t"
        "ldp	x19, x20, [x2]\n\t"
        "ldp	x21, x22, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldr	x0, [x29, #16]\n\t"
        "ldr	x1, [x29, #48]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x1]\n\t"
        "ldp	x17, x18, [x1, #16]\n\t"
        "ldp	x19, x20, [x2]\n\t"
        "ldp	x21, x22, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldr	x0, [x29, #24]\n\t"
        "ldr	x1, [x29, #64]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x2]\n\t"
        "ldp	x17, x18, [x2, #16]\n\t"
        "ldp	x19, x20, [x1]\n\t"
        "ldp	x21, x22, [x1, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldr	x0, [x29, #32]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        "ldr	x2, [x29, #48]\n\t"
        /* Multiply */
        "ldp	x11, x16, [x1]\n\t"
        "ldp	x17, x18, [x1, #16]\n\t"
        "ldp	x19, x20, [x2]\n\t"
        "ldp	x21, x22, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x3, x11, x19\n\t"
        "umulh	x4, x11, x19\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x11, x20\n\t"
        "umulh	x5, x11, x20\n\t"
        "adds	x4, x4, x12\n\t"
        "adc	x5, x5, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x16, x19\n\t"
        "umulh	x13, x16, x19\n\t"
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x13\n\t"
        "adc	x6, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x11, x21\n\t"
        "umulh	x13, x11, x21\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x16, x20\n\t"
        "umulh	x13, x16, x20\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x17, x19\n\t"
        "umulh	x13, x17, x19\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x11, x22\n\t"
        "umulh	x13, x11, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x16, x21\n\t"
        "umulh	x13, x16, x21\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x17, x20\n\t"
        "umulh	x13, x17, x20\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x18, x19\n\t"
        "umulh	x13, x18, x19\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x16, x22\n\t"
        "umulh	x13, x16, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x17, x21\n\t"
        "umulh	x13, x17, x21\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x18, x20\n\t"
        "umulh	x13, x18, x20\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x17, x22\n\t"
        "umulh	x13, x17, x22\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x18, x21\n\t"
        "umulh	x13, x18, x21\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x18, x22\n\t"
        "umulh	x13, x18, x22\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x7\n\t"
        "umulh	x7, x12, x7\n\t"
        "adds	x3, x3, x13\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adcs	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x14, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x7\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x6, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x6, x6, #0x7fffffffffffffff\n\t"
        "adds	x3, x3, x14\n\t"
        "adcs	x4, x4, xzr\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adc	x6, x6, xzr\n\t"
        /* Store */
        "stp	x3, x4, [x0]\n\t"
        "stp	x5, x6, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #0x50\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [rt] "+r" (rt), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz), [pt] "+r" (pt)
        :
        : "memory", "x12", "x13", "x14", "x15", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22"
    );
}

void fe_ge_dbl(fe rx, fe ry, fe rz, fe rt, const fe px, const fe py, const fe pz)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-80]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[rx], [x29, #16]\n\t"
        "str	%[ry], [x29, #24]\n\t"
        "str	%[rz], [x29, #32]\n\t"
        "str	%[rt], [x29, #40]\n\t"
        "str	%[px], [x29, #48]\n\t"
        "str	%[py], [x29, #56]\n\t"
        "str	%[pz], [x29, #64]\n\t"
        "ldr	x1, [x29, #48]\n\t"
        /* Square */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x5, x20, x21\n\t"
        "umulh	x6, x20, x21\n\t"
        /*  A[0] * A[2] */
        "mul	x12, x20, x22\n\t"
        "umulh	x7, x20, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x12, x20, x23\n\t"
        "umulh	x8, x20, x23\n\t"
        "adds	x7, x7, x12\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x12, x21, x22\n\t"
        "umulh	x13, x21, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x12, x21, x23\n\t"
        "umulh	x13, x21, x23\n\t"
        "adds	x8, x8, x12\n\t"
        "adc	x9, x9, x13\n\t"
        /*  A[2] * A[3] */
        "mul	x12, x22, x23\n\t"
        "umulh	x10, x22, x23\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, xzr\n\t"
        /* Double */
        "adds	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adcs	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x4, x20, x20\n\t"
        "umulh	x15, x20, x20\n\t"
        /*  A[1] * A[1] */
        "mul	x12, x21, x21\n\t"
        "umulh	x13, x21, x21\n\t"
        "adds	x5, x5, x15\n\t"
        "adcs	x6, x6, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x12, x22, x22\n\t"
        "umulh	x13, x22, x22\n\t"
        "adds	x7, x7, x15\n\t"
        "adcs	x8, x8, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x12, x23, x23\n\t"
        "umulh	x13, x23, x23\n\t"
        "adds	x9, x9, x15\n\t"
        "adcs	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x0, [x29, #32]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        /* Square */
        "ldp	x20, x21, [x2]\n\t"
        "ldp	x22, x23, [x2, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x5, x20, x21\n\t"
        "umulh	x6, x20, x21\n\t"
        /*  A[0] * A[2] */
        "mul	x12, x20, x22\n\t"
        "umulh	x7, x20, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x12, x20, x23\n\t"
        "umulh	x8, x20, x23\n\t"
        "adds	x7, x7, x12\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x12, x21, x22\n\t"
        "umulh	x13, x21, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x12, x21, x23\n\t"
        "umulh	x13, x21, x23\n\t"
        "adds	x8, x8, x12\n\t"
        "adc	x9, x9, x13\n\t"
        /*  A[2] * A[3] */
        "mul	x12, x22, x23\n\t"
        "umulh	x10, x22, x23\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, xzr\n\t"
        /* Double */
        "adds	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adcs	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x4, x20, x20\n\t"
        "umulh	x15, x20, x20\n\t"
        /*  A[1] * A[1] */
        "mul	x12, x21, x21\n\t"
        "umulh	x13, x21, x21\n\t"
        "adds	x5, x5, x15\n\t"
        "adcs	x6, x6, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x12, x22, x22\n\t"
        "umulh	x13, x22, x22\n\t"
        "adds	x7, x7, x15\n\t"
        "adcs	x8, x8, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x12, x23, x23\n\t"
        "umulh	x13, x23, x23\n\t"
        "adds	x9, x9, x15\n\t"
        "adcs	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x0, [x29, #24]\n\t"
        /* Add */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "ldp	x8, x9, [x2]\n\t"
        "ldp	x10, x11, [x2, #16]\n\t"
        "adds	x4, x4, x8\n\t"
        "adcs	x5, x5, x9\n\t"
        "adcs	x6, x6, x10\n\t"
        "adc	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x7, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x4, x4, x12\n\t"
        "sbcs	x5, x5, x15\n\t"
        "sbcs	x6, x6, x15\n\t"
        "sbc	x7, x7, x13\n\t"
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        /* Square */
        "ldp	x20, x21, [x0]\n\t"
        "ldp	x22, x23, [x0, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x5, x20, x21\n\t"
        "umulh	x6, x20, x21\n\t"
        /*  A[0] * A[2] */
        "mul	x12, x20, x22\n\t"
        "umulh	x7, x20, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x12, x20, x23\n\t"
        "umulh	x8, x20, x23\n\t"
        "adds	x7, x7, x12\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x12, x21, x22\n\t"
        "umulh	x13, x21, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x12, x21, x23\n\t"
        "umulh	x13, x21, x23\n\t"
        "adds	x8, x8, x12\n\t"
        "adc	x9, x9, x13\n\t"
        /*  A[2] * A[3] */
        "mul	x12, x22, x23\n\t"
        "umulh	x10, x22, x23\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, xzr\n\t"
        /* Double */
        "adds	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adcs	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x4, x20, x20\n\t"
        "umulh	x15, x20, x20\n\t"
        /*  A[1] * A[1] */
        "mul	x12, x21, x21\n\t"
        "umulh	x13, x21, x21\n\t"
        "adds	x5, x5, x15\n\t"
        "adcs	x6, x6, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x12, x22, x22\n\t"
        "umulh	x13, x22, x22\n\t"
        "adds	x7, x7, x15\n\t"
        "adcs	x8, x8, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x12, x23, x23\n\t"
        "umulh	x13, x23, x23\n\t"
        "adds	x9, x9, x15\n\t"
        "adcs	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x1, [x29, #32]\n\t"
        "ldr	x2, [x29, #16]\n\t"
        /* Add */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "ldp	x8, x9, [x2]\n\t"
        "ldp	x10, x11, [x2, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        /* Sub */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldr	x0, [x29, #64]\n\t"
        /* Square * 2 */
        "ldp	x20, x21, [x0]\n\t"
        "ldp	x22, x23, [x0, #16]\n\t"
        /*  A[0] * A[1] */
        "mul	x5, x20, x21\n\t"
        "umulh	x6, x20, x21\n\t"
        /*  A[0] * A[2] */
        "mul	x12, x20, x22\n\t"
        "umulh	x7, x20, x22\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, xzr\n\t"
        /*  A[0] * A[3] */
        "mul	x12, x20, x23\n\t"
        "umulh	x8, x20, x23\n\t"
        "adds	x7, x7, x12\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[1] * A[2] */
        "mul	x12, x21, x22\n\t"
        "umulh	x13, x21, x22\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * A[3] */
        "mul	x12, x21, x23\n\t"
        "umulh	x13, x21, x23\n\t"
        "adds	x8, x8, x12\n\t"
        "adc	x9, x9, x13\n\t"
        /*  A[2] * A[3] */
        "mul	x12, x22, x23\n\t"
        "umulh	x10, x22, x23\n\t"
        "adds	x9, x9, x12\n\t"
        "adc	x10, x10, xzr\n\t"
        /* Double */
        "adds	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adcs	x7, x7, x7\n\t"
        "adcs	x8, x8, x8\n\t"
        "adcs	x9, x9, x9\n\t"
        "adcs	x10, x10, x10\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[0] * A[0] */
        "mul	x4, x20, x20\n\t"
        "umulh	x15, x20, x20\n\t"
        /*  A[1] * A[1] */
        "mul	x12, x21, x21\n\t"
        "umulh	x13, x21, x21\n\t"
        "adds	x5, x5, x15\n\t"
        "adcs	x6, x6, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[2] * A[2] */
        "mul	x12, x22, x22\n\t"
        "umulh	x13, x22, x22\n\t"
        "adds	x7, x7, x15\n\t"
        "adcs	x8, x8, x12\n\t"
        "adc	x15, x13, xzr\n\t"
        /*  A[3] * A[3] */
        "mul	x12, x23, x23\n\t"
        "umulh	x13, x23, x23\n\t"
        "adds	x9, x9, x15\n\t"
        "adcs	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Double and Reduce */
        "mov	x12, #0x169\n\t"
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "lsr	x15, x11, #61\n\t"
        "extr	x11, x11, x10, #62\n\t"
        "extr	x10, x10, x9, #62\n\t"
        "extr	x9, x9, x8, #62\n\t"
        "extr	x8, x8, x7, #62\n\t"
        "extr	x7, x7, x6, #63\n\t"
        "extr	x6, x6, x5, #63\n\t"
        "extr	x5, x5, x4, #63\n\t"
        "lsl	x4, x4, #1\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Two left, only one right */
        "and	x11, x11, #0x7fffffffffffffff\n\t"
        /*  Multiply top bits by 19*19 */
        "mul	x15, x15, x12\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x4, x4, x15\n\t"
        "adcs	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x0, [x29, #32]\n\t"
        /* Sub */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldp	x29, x30, [sp], #0x50\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [rt] "+r" (rt), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz)
        :
        : "memory", "x12", "x13", "x14", "x15", "x7", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23"
    );
}

void fe_ge_madd(fe rx, fe ry, fe rz, fe rt, const fe px, const fe py, const fe pz, const fe pt, const fe qxy2d, const fe qyplusx, const fe qyminusx)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-80]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[rx], [x29, #16]\n\t"
        "str	%[ry], [x29, #24]\n\t"
        "str	%[rz], [x29, #32]\n\t"
        "str	%[rt], [x29, #40]\n\t"
        "str	%[px], [x29, #48]\n\t"
        "str	%[py], [x29, #56]\n\t"
        "str	%[pz], [x29, #64]\n\t"
        "str	%[pt], [x29, #72]\n\t"
        "ldr	x1, [x29, #24]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        "ldr	x3, [x29, #48]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x3]\n\t"
        "ldp	x10, x11, [x3, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x2, [x29, #32]\n\t"
        "ldr	x3, [x29, #168]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x0]\n\t"
        "ldp	x22, x23, [x0, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldr	x0, [x29, #176]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x0]\n\t"
        "ldp	x26, x27, [x0, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x0, [x29, #40]\n\t"
        "ldr	x1, [x29, #160]\n\t"
        "ldr	x3, [x29, #72]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x0, [x29, #24]\n\t"
        "ldr	x1, [x29, #16]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x0, [x29, #64]\n\t"
        /* Double */
        "ldp	x4, x5, [x0]\n\t"
        "ldp	x6, x7, [x0, #16]\n\t"
        "adds	x4, x4, x4\n\t"
        "adcs	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adc	x7, x7, x7\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x7, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x4, x4, x12\n\t"
        "sbcs	x5, x5, x15\n\t"
        "sbcs	x6, x6, x15\n\t"
        "sbc	x7, x7, x13\n\t"
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldr	x0, [x29, #40]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x2]\n\t"
        "stp	x18, x19, [x2, #16]\n\t"
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #0x50\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [rt] "+r" (rt), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz), [pt] "+r" (pt)
        :
        : "memory", "x12", "x13", "x14", "x15", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27"
    );
    (void)qxy2d;
    (void)qyplusx;
    (void)qyminusx;
}

void fe_ge_msub(fe rx, fe ry, fe rz, fe rt, const fe px, const fe py, const fe pz, const fe pt, const fe qxy2d, const fe qyplusx, const fe qyminusx)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-80]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[rx], [x29, #16]\n\t"
        "str	%[ry], [x29, #24]\n\t"
        "str	%[rz], [x29, #32]\n\t"
        "str	%[rt], [x29, #40]\n\t"
        "str	%[px], [x29, #48]\n\t"
        "str	%[py], [x29, #56]\n\t"
        "str	%[pz], [x29, #64]\n\t"
        "str	%[pt], [x29, #72]\n\t"
        "ldr	x1, [x29, #24]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        "ldr	x3, [x29, #48]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x3]\n\t"
        "ldp	x10, x11, [x3, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x2, [x29, #32]\n\t"
        "ldr	x3, [x29, #176]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x0]\n\t"
        "ldp	x22, x23, [x0, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldr	x0, [x29, #168]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x0]\n\t"
        "ldp	x26, x27, [x0, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x0, [x29, #40]\n\t"
        "ldr	x1, [x29, #160]\n\t"
        "ldr	x3, [x29, #72]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x1, [x29, #24]\n\t"
        "ldr	x3, [x29, #16]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x1]\n\t"
        "ldp	x10, x11, [x1, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x1]\n\t"
        "stp	x18, x19, [x1, #16]\n\t"
        "stp	x4, x5, [x3]\n\t"
        "stp	x6, x7, [x3, #16]\n\t"
        "ldr	x1, [x29, #64]\n\t"
        /* Double */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "adds	x4, x4, x4\n\t"
        "adcs	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adc	x7, x7, x7\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x7, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x4, x4, x12\n\t"
        "sbcs	x5, x5, x15\n\t"
        "sbcs	x6, x6, x15\n\t"
        "sbc	x7, x7, x13\n\t"
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldp	x29, x30, [sp], #0x50\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [rt] "+r" (rt), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz), [pt] "+r" (pt)
        :
        : "memory", "x12", "x13", "x14", "x15", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27"
    );
    (void)qxy2d;
    (void)qyplusx;
    (void)qyminusx;
}

void fe_ge_add(fe rx, fe ry, fe rz, fe rt, const fe px, const fe py, const fe pz, const fe pt, const fe qz, const fe qt2d, const fe qyplusx, const fe qyminusx)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-112]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[rx], [x29, #16]\n\t"
        "str	%[ry], [x29, #24]\n\t"
        "str	%[rz], [x29, #32]\n\t"
        "str	%[rt], [x29, #40]\n\t"
        "str	%[px], [x29, #48]\n\t"
        "str	%[py], [x29, #56]\n\t"
        "str	%[pz], [x29, #64]\n\t"
        "str	%[pt], [x29, #72]\n\t"
        "ldr	x1, [x29, #24]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        "ldr	x3, [x29, #48]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x3]\n\t"
        "ldp	x10, x11, [x3, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x2, [x29, #32]\n\t"
        "ldr	x3, [x29, #208]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x0]\n\t"
        "ldp	x22, x23, [x0, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldr	x2, [x29, #216]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x2]\n\t"
        "ldp	x26, x27, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        "ldr	x2, [x29, #200]\n\t"
        "ldr	x3, [x29, #72]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x2]\n\t"
        "ldp	x22, x23, [x2, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x1, [x29, #64]\n\t"
        "ldr	x2, [x29, #192]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x2]\n\t"
        "ldp	x26, x27, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "add	x1, x29, #80\n\t"
        /* Double */
        "ldp	x4, x5, [x0]\n\t"
        "ldp	x6, x7, [x0, #16]\n\t"
        "adds	x4, x4, x4\n\t"
        "adcs	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adc	x7, x7, x7\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x7, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x4, x4, x12\n\t"
        "sbcs	x5, x5, x15\n\t"
        "sbcs	x6, x6, x15\n\t"
        "sbc	x7, x7, x13\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x2, [x29, #24]\n\t"
        "ldr	x3, [x29, #32]\n\t"
        /* Add */
        "ldp	x4, x5, [x3]\n\t"
        "ldp	x6, x7, [x3, #16]\n\t"
        "ldp	x8, x9, [x2]\n\t"
        "ldp	x10, x11, [x2, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x2]\n\t"
        "stp	x18, x19, [x2, #16]\n\t"
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x0, [x29, #40]\n\t"
        /* Add */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x3]\n\t"
        "stp	x18, x19, [x3, #16]\n\t"
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldp	x29, x30, [sp], #0x70\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [rt] "+r" (rt), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz), [pt] "+r" (pt)
        :
        : "memory", "x12", "x13", "x14", "x15", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27"
    );
    (void)qz;
    (void)qt2d;
    (void)qyplusx;
    (void)qyminusx;
}

void fe_ge_sub(fe rx, fe ry, fe rz, fe rt, const fe px, const fe py, const fe pz, const fe pt, const fe qz, const fe qt2d, const fe qyplusx, const fe qyminusx)
{
    __asm__ __volatile__ (
        "stp	x29, x30, [sp, #-112]!\n\t"
        "add	x29, sp, #0\n\t"
        "str	%[rx], [x29, #16]\n\t"
        "str	%[ry], [x29, #24]\n\t"
        "str	%[rz], [x29, #32]\n\t"
        "str	%[rt], [x29, #40]\n\t"
        "str	%[px], [x29, #48]\n\t"
        "str	%[py], [x29, #56]\n\t"
        "str	%[pz], [x29, #64]\n\t"
        "str	%[pt], [x29, #72]\n\t"
        "ldr	x1, [x29, #24]\n\t"
        "ldr	x2, [x29, #56]\n\t"
        "ldr	x3, [x29, #48]\n\t"
        /* Add */
        "ldp	x4, x5, [x2]\n\t"
        "ldp	x6, x7, [x2, #16]\n\t"
        "ldp	x8, x9, [x3]\n\t"
        "ldp	x10, x11, [x3, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x2, [x29, #32]\n\t"
        "ldr	x3, [x29, #216]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x0]\n\t"
        "ldp	x22, x23, [x0, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x2]\n\t"
        "stp	x6, x7, [x2, #16]\n\t"
        "ldr	x2, [x29, #208]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x2]\n\t"
        "ldp	x26, x27, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x1, [x29, #40]\n\t"
        "ldr	x2, [x29, #200]\n\t"
        "ldr	x3, [x29, #72]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x2]\n\t"
        "ldp	x22, x23, [x2, #16]\n\t"
        "ldp	x24, x25, [x3]\n\t"
        "ldp	x26, x27, [x3, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x1, [x29, #64]\n\t"
        "ldr	x2, [x29, #192]\n\t"
        /* Multiply */
        "ldp	x20, x21, [x1]\n\t"
        "ldp	x22, x23, [x1, #16]\n\t"
        "ldp	x24, x25, [x2]\n\t"
        "ldp	x26, x27, [x2, #16]\n\t"
        /*  A[0] * B[0] */
        "mul	x4, x20, x24\n\t"
        "umulh	x5, x20, x24\n\t"
        /*  A[0] * B[1] */
        "mul	x12, x20, x25\n\t"
        "umulh	x6, x20, x25\n\t"
        "adds	x5, x5, x12\n\t"
        "adc	x6, x6, xzr\n\t"
        /*  A[1] * B[0] */
        "mul	x12, x21, x24\n\t"
        "umulh	x13, x21, x24\n\t"
        "adds	x5, x5, x12\n\t"
        "adcs	x6, x6, x13\n\t"
        "adc	x7, xzr, xzr\n\t"
        /*  A[0] * B[2] */
        "mul	x12, x20, x26\n\t"
        "umulh	x13, x20, x26\n\t"
        "adds	x6, x6, x12\n\t"
        "adc	x7, x7, x13\n\t"
        /*  A[1] * B[1] */
        "mul	x12, x21, x25\n\t"
        "umulh	x13, x21, x25\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, xzr, xzr\n\t"
        /*  A[2] * B[0] */
        "mul	x12, x22, x24\n\t"
        "umulh	x13, x22, x24\n\t"
        "adds	x6, x6, x12\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x8, x8, xzr\n\t"
        /*  A[0] * B[3] */
        "mul	x12, x20, x27\n\t"
        "umulh	x13, x20, x27\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, xzr, xzr\n\t"
        /*  A[1] * B[2] */
        "mul	x12, x21, x26\n\t"
        "umulh	x13, x21, x26\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[2] * B[1] */
        "mul	x12, x22, x25\n\t"
        "umulh	x13, x22, x25\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[3] * B[0] */
        "mul	x12, x23, x24\n\t"
        "umulh	x13, x23, x24\n\t"
        "adds	x7, x7, x12\n\t"
        "adcs	x8, x8, x13\n\t"
        "adc	x9, x9, xzr\n\t"
        /*  A[1] * B[3] */
        "mul	x12, x21, x27\n\t"
        "umulh	x13, x21, x27\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, xzr, xzr\n\t"
        /*  A[2] * B[2] */
        "mul	x12, x22, x26\n\t"
        "umulh	x13, x22, x26\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[3] * B[1] */
        "mul	x12, x23, x25\n\t"
        "umulh	x13, x23, x25\n\t"
        "adds	x8, x8, x12\n\t"
        "adcs	x9, x9, x13\n\t"
        "adc	x10, x10, xzr\n\t"
        /*  A[2] * B[3] */
        "mul	x12, x22, x27\n\t"
        "umulh	x13, x22, x27\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, xzr, xzr\n\t"
        /*  A[3] * B[2] */
        "mul	x12, x23, x26\n\t"
        "umulh	x13, x23, x26\n\t"
        "adds	x9, x9, x12\n\t"
        "adcs	x10, x10, x13\n\t"
        "adc	x11, x11, xzr\n\t"
        /*  A[3] * B[3] */
        "mul	x12, x23, x27\n\t"
        "umulh	x13, x23, x27\n\t"
        "adds	x10, x10, x12\n\t"
        "adc	x11, x11, x13\n\t"
        /* Reduce */
        /*  Move top half into t4-t7 and remove top bit from t3 */
        "extr	x11, x11, x10, #63\n\t"
        "extr	x10, x10, x9, #63\n\t"
        "extr	x9, x9, x8, #63\n\t"
        "extr	x8, x8, x7, #63\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        /*  Multiply top half by 19 */
        "mov	x12, #19\n\t"
        "mul	x13, x12, x8\n\t"
        "umulh	x8, x12, x8\n\t"
        "adds	x4, x4, x13\n\t"
        "mul	x13, x12, x9\n\t"
        "umulh	x9, x12, x9\n\t"
        "adcs	x5, x5, x13\n\t"
        "mul	x13, x12, x10\n\t"
        "umulh	x10, x12, x10\n\t"
        "adcs	x6, x6, x13\n\t"
        "mul	x13, x12, x11\n\t"
        "umulh	x14, x12, x11\n\t"
        "adcs	x7, x7, x13\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Add remaining product results in */
        "adds	x5, x5, x8\n\t"
        "adcs	x6, x6, x9\n\t"
        "adcs	x7, x7, x10\n\t"
        "adc	x14, x14, xzr\n\t"
        /*  Overflow */
        "extr	x14, x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Reduce if top bit set */
        "lsr	x14, x7, #63\n\t"
        "mul	x14, x14, x12\n\t"
        "and	x7, x7, #0x7fffffffffffffff\n\t"
        "adds	x4, x4, x14\n\t"
        "adcs	x5, x5, xzr\n\t"
        "adcs	x6, x6, xzr\n\t"
        "adc	x7, x7, xzr\n\t"
        /* Store */
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "add	x1, x29, #80\n\t"
        /* Double */
        "ldp	x4, x5, [x0]\n\t"
        "ldp	x6, x7, [x0, #16]\n\t"
        "adds	x4, x4, x4\n\t"
        "adcs	x5, x5, x5\n\t"
        "adcs	x6, x6, x6\n\t"
        "adc	x7, x7, x7\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x7, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x4, x4, x12\n\t"
        "sbcs	x5, x5, x15\n\t"
        "sbcs	x6, x6, x15\n\t"
        "sbc	x7, x7, x13\n\t"
        "stp	x4, x5, [x1]\n\t"
        "stp	x6, x7, [x1, #16]\n\t"
        "ldr	x2, [x29, #24]\n\t"
        "ldr	x3, [x29, #32]\n\t"
        /* Add */
        "ldp	x4, x5, [x3]\n\t"
        "ldp	x6, x7, [x3, #16]\n\t"
        "ldp	x8, x9, [x2]\n\t"
        "ldp	x10, x11, [x2, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x2]\n\t"
        "stp	x18, x19, [x2, #16]\n\t"
        "stp	x4, x5, [x0]\n\t"
        "stp	x6, x7, [x0, #16]\n\t"
        "ldr	x0, [x29, #40]\n\t"
        /* Add */
        "ldp	x4, x5, [x1]\n\t"
        "ldp	x6, x7, [x1, #16]\n\t"
        "ldp	x8, x9, [x0]\n\t"
        "ldp	x10, x11, [x0, #16]\n\t"
        "adds	x16, x4, x8\n\t"
        "adcs	x17, x5, x9\n\t"
        "adcs	x18, x6, x10\n\t"
        "adc	x19, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "asr	x15, x19, #63\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Sub modulus (if overflow) */
        "subs	x16, x16, x12\n\t"
        "sbcs	x17, x17, x15\n\t"
        "sbcs	x18, x18, x15\n\t"
        "sbc	x19, x19, x13\n\t"
        /* Sub */
        "subs	x4, x4, x8\n\t"
        "sbcs	x5, x5, x9\n\t"
        "sbcs	x6, x6, x10\n\t"
        "sbcs	x7, x7, x11\n\t"
        "mov	x12, #-19\n\t"
        "csetm	x15, cc\n\t"
        /*   Mask the modulus */
        "and	x12, x15, x12\n\t"
        "and	x13, x15, #0x7fffffffffffffff\n\t"
        /*   Add modulus (if underflow) */
        "adds	x4, x4, x12\n\t"
        "adcs	x5, x5, x15\n\t"
        "adcs	x6, x6, x15\n\t"
        "adc	x7, x7, x13\n\t"
        "stp	x16, x17, [x0]\n\t"
        "stp	x18, x19, [x0, #16]\n\t"
        "stp	x4, x5, [x3]\n\t"
        "stp	x6, x7, [x3, #16]\n\t"
        "ldp	x29, x30, [sp], #0x70\n\t"
        : [rx] "+r" (rx), [ry] "+r" (ry), [rz] "+r" (rz), [rt] "+r" (rt), [px] "+r" (px), [py] "+r" (py), [pz] "+r" (pz), [pt] "+r" (pt)
        :
        : "memory", "x12", "x13", "x14", "x15", "x8", "x9", "x10", "x11", "x16", "x17", "x18", "x19", "x20", "x21", "x22", "x23", "x24", "x25", "x26", "x27"
    );
    (void)qz;
    (void)qt2d;
    (void)qyplusx;
    (void)qyminusx;
}

